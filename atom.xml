<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[iCen DiaMondinG]]></title>
  <link href="http://joycn.github.com/atom.xml" rel="self"/>
  <link href="http://joycn.github.com/"/>
  <updated>2013-03-10T08:58:00+08:00</updated>
  <id>http://joycn.github.com/</id>
  <author>
    <name><![CDATA[joycn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[有关linux kernel timer的问题]]></title>
    <link href="http://joycn.github.com/blog/2013/03/08/kernel-timer/"/>
    <updated>2013-03-08T22:59:00+08:00</updated>
    <id>http://joycn.github.com/blog/2013/03/08/kernel-timer</id>
    <content type="html"><![CDATA[<p>最近在做优化时,发现居然是在linux kernel timer的使用方面造成的性能瓶颈.</p>

<p>于是顺便就查了下,目前2.6内核中有关timer的一点简单介绍.</p>

<p>之前一直想当然以为说硬件发出的时间中断请求,跟其他的请求一样,只能被某一个CPU处理.没想过这个问题,然后最近在做优化的时候,突然意识到代码里用了太多的timer,而所有cpu在softirq上的消耗居然差不多.然后觉得似乎不是自己想的那样.然后就去网上查了下资料.发现自己还真理解错了</p>

<!-- more -->


<h2>硬件中断的一些内容</h2>

<p>关于硬件中断的产生,这里先简单了解下.现在硬件时钟中断的产生,主要是通过PIT或者HPET来产生.这种硬件中断只能被cpu0来处理.中断号为0.这个中断的对应的处理函数时timer_interrupt.主要功能是做一些变量值的更新(这个先不关心,主要关心的是kernel中timer是怎么回事,所以这里先忽略)然后调用do_timer_interrupt函数来更新jiffies_64以及更新系统时间.后面会调到apic_timer_interrupt这个函数,这个函数涉及到local timer .然后会调到smp_apic_timer_interrupt这个函数.smp_local_timer_interrupt这个函数就是关于per cpu timer处理的函数.smp_local_timer_interrupt中的update_process_times函数主要就是来检查当前进程运行了多久,然后调用raise_softirq来让本地CPU来处理time软中断.对应的处理函数就是run_timer_softirq.这个是我们这里主要关注的地方.然后If some old version of an RCU-protected data structure has to be reclaimed, checks
whether the local CPU has gone through a quiescent state and invokes
tasklet_schedule( ) to activate the rcu_tasklet tasklet of the local CPU,再scheduler_tick减少当前进程的时间片,并且检查时间片是否已经耗光了.</p>

<h2>软中断以及timer_list</h2>

<p>终于到今天关注的重点了.timer_list相关的内容:</p>

<p>timer_list的一些函数这里就不介绍了,用了都知道.</p>

<p>里面肯定涉及到一个time时间的比较,这里我们说时刻a在时刻b之后，就意味着时间值a≥b。Linux强烈推荐用户使用它所定义的下列4个.为什么呢?因为涉及到jiffies溢出的问题,因为jiffies是一个32位的变量,所以还是很容易溢出的,当溢出了,比较起来肯定会有问题的,所以,内核就用定义了一下几个宏.其实就是类型转化成有符号long型,然后直接做比较(毕竟溢出后,负数就变成正数了,肯定比较起来没问题的,不过.溢出很多,轮一圈当然就比较不出来了.)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#define time_after(a,b) ((long)(b) - (long)(a) &lt; 0)
</span><span class='line'>#define time_before(a,b) time_after(b,a)
</span><span class='line'>#define time_after_eq(a,b) ((long)(a) - (long)(b) >= 0)
</span><span class='line'>#define time_before_eq(a,b) time_after_eq(b,a)</span></code></pre></td></tr></table></div></figure>


<h3>动态内核定时器机制的原理</h3>

<p>Linux是怎样为其内核定时器机制提供动态扩展能力的呢？其关键就在于“定时器向量”的概念。所谓“定时器向量”就是指这样一条双向循环定时器队列（对列中的每一个元素都是一个timer_list结构）：对列中的所有定时器都在同一个时刻到期，也即对列中的每一个timer_list结构都具有相同的expires值。显然，可以用一个timer_list结构类型的指针来表示一个定时器向量。显然，定时器expires成员的值与jiffies变量的差值决定了一个定时器将在多长时间后到期。在32位系统中，这个时间差值的最大值应该是0xffffffff。因此如果是基于“定时器向量”基本定义，内核将至少要维护0xffffffff个timer_list结构类型的指针，这显然是不现实的。另一方面，从内核本身这个角度看，它所关心的定时器显然不是那些已经过期而被执行过的定时器（这些定时器完全可以被丢弃），也不是那些要经过很长时间才会到期的定时器，而是那些当前已经到期或者马上就要到期的定时器（注意！时间间隔是以滴答次数为计数单位的）。基于上述考虑，并假定一个定时器要经过interval个时钟滴答后才到期（interval＝expires－jiffies），则Linux采用了下列思想来实现其动态内核定时器机制：对于那些0≤interval≤255的定时器，Linux严格按照定时器向量的基本语义来组织这些定时器，也即Linux内核最关心那些在接下来的255个时钟节拍内就要到期的定时器，因此将它们按照各自不同的expires值组织成256个定时器向量。而对于那些256≤interval≤0xffffffff的定时器，由于他们离到期还有一段时间，因此内核并不关心他们，而是将它们以一种扩展的定时器向量语义（或称为“松散的定时器向量语义”）进行组织。所谓“松散的定时器向量语义”就是指：各定时器的expires值可以互不相同的一个定时器队列。具体的组织方案可以分为两大部分</p>

<p>（1）对于内核最关心的、interval值在［0，255］之间的前256个定时器向量，内核是这样组织它们的：这256个定时器向量被组织在一起组成一个定时器向量数组，并作为数据结构timer_vec_root的一部分，该数据结构定义在kernel/timer.c文件中，如下述代码段所示：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/*
</span><span class='line'> * per-CPU timer vector definitions:
</span><span class='line'> */    
</span><span class='line'>#define TVN_BITS (CONFIG_BASE_SMALL ? 4 : 6)
</span><span class='line'>#define TVR_BITS (CONFIG_BASE_SMALL ? 6 : 8)
</span><span class='line'>#define TVN_SIZE (1 &lt;&lt; TVN_BITS)
</span><span class='line'>#define TVR_SIZE (1 &lt;&lt; TVR_BITS)
</span><span class='line'>#define TVN_MASK (TVN_SIZE - 1)
</span><span class='line'>#define TVR_MASK (TVR_SIZE - 1)
</span><span class='line'>
</span><span class='line'>struct tvec {
</span><span class='line'>    struct list_head vec[TVN_SIZE];            
</span><span class='line'>};
</span><span class='line'>
</span><span class='line'>struct tvec_root {
</span><span class='line'>    struct list_head vec[TVR_SIZE];    
</span><span class='line'>};
</span><span class='line'>
</span><span class='line'>struct tvec_base {
</span><span class='line'>    spinlock_t lock;
</span><span class='line'>    struct timer_list *running_timer;
</span><span class='line'>    unsigned long timer_jiffies;   
</span><span class='line'>    unsigned long next_timer; 
</span><span class='line'>    struct tvec_root tv1;     
</span><span class='line'>    struct tvec tv2;
</span><span class='line'>    struct tvec tv3;
</span><span class='line'>    struct tvec tv4;
</span><span class='line'>    struct tvec tv5;
</span><span class='line'>} ____cacheline_aligned;</span></code></pre></td></tr></table></div></figure>


<p>基于数据结构timer_vec_root，Linux定义了一个全局变量tv1，以表示内核所关心的前256个定时器向量。这样内核在处理是否有到期定时器时，它就只从定时器向量数组tv1.vec［256］中的某个定时器向量内进行扫描。而tv1的index字段则指定当前正在扫描定时器向量数组tv1.vec［256］中的哪一个定时器向量，也即该数组的索引，其初值为0，最大值为255（以256为模）。每个时钟节拍时index字段都会加1。显然，index字段所指定的定时器向量tv1.vec［index］中包含了当前时钟节拍内已经到期的所有动态定时器。而定时器向量tv1.vec［index＋k］则包含了接下来第k个时钟节拍时刻将到期的所有动态定时器。当index值又重新变为0时，就意味着内核已经扫描了tv1变量中的所有256个定时器向量。在这种情况下就必须将那些以松散定时器向量语义来组织的定时器向量补充到tv1中来。</p>

<p>（2）而对于内核不关心的、interval值在［0xff，0xffffffff］之间的定时器，它们的到期紧迫程度也随其interval值的不同而不同。显然interval值越小，定时器紧迫程度也越高。因此在将它们以松散定时器向量进行组织时也应该区别对待。通常，定时器的interval值越小，它所处的定时器向量的松散度也就越低（也即向量中的各定时器的expires值相差越小）；而interval值越大，它所处的定时器向量的松散度也就越大（也即向量中的各定时器的expires值相差越大）。内核规定，对于那些满足条件：0x100≤interval≤0x3fff的定时器，只要表达式（interval>>8）具有相同值的定时器都将被组织在同一个松散定时器向量中。因此，为组织所有满足条件0x100≤interval≤0x3fff的定时器，就需要26＝64个松散定时器向量。同样地，为方便起见，这64个松散定时器向量也放在一起形成数组，并作为数据结构timer_vec的一部分。基于数据结构timer_vec，Linux定义了全局变量tv2，来表示这64条松散定时器向量。如上述代码段所示。对于那些满足条件0x4000≤interval≤0xfffff的定时器，只要表达式（interval>>8＋6）的值相同的定时器都将被放在同一个松散定时器向量中。同样，要组织所有满足条件0x4000≤interval≤0xfffff的定时器，也需要26＝64个松散定时器向量。类似地，这64个松散定时器向量也可以用一个timer_vec结构来描述，相应地Linux定义了tv3全局变量来表示这64个松散定时器向量。对于那些满足条件0x100000≤interval≤0x3ffffff的定时器，只要表达式（interval>>8＋6＋6）的值相同的定时器都将被放在同一个松散定时器向量中。同样，要组织所有满足条件0x100000≤interval≤0x3ffffff的定时器，也需要26＝64个松散定时器向量。类似地，这64个松散定时器向量也可以用一个timer_vec结构来描述，相应地Linux定义了tv4全局变量来表示这64个松散定时器向量。对于那些满足条件0x4000000≤interval≤0xffffffff的定时器，只要表达式（interval>>8＋6＋6＋6）的值相同的定时器都将被放在同一个松散定时器向量中。同样，要组织所有满足条件0x4000000≤interval≤0xffffffff的定时器，也需要26＝64个松散定时器向量。类似地，这64个松散定时器向量也可以用一个timer_vec结构来描述，相应地Linux定义了tv5全局变量来表示这64个松散定时器向量。最后，为了引用方便，Linux定义了一个指针数组tvecs[]，来分别指向tv1、tv2、…、tv5结构变量。如上述代码所示。</p>

<h2>内核动态定时器机制的实现</h2>

<p>在内核动态定时器机制的实现中，有三个操作时非常重要的：</p>

<p>（1）将一个定时器插入到它应该所处的定时器向量中。</p>

<p>（2）定时器的迁移，也即将一个定时器从它原来所处的定时器向量迁移到另一个定时器向量中。</p>

<p>（3）扫描并执行当前已经到期的定时器。</p>

<h3>动态定时器机制的初始化</h3>

<p>函数init_timers_cpu()实现对动态定时器机制的初始化。由于2.6以后,tvec_base变成了percpu的数据类型,所以就要对在cpu处于CPU_UP_PREPARE_FROZEN状态的时候对相应的数据结构进行初始化.</p>

<h3>动态定时器的时钟滴答基准timer_jiffies</h3>

<p>由于动态定时器是在时钟中断的Bottom Half中被执行的，而从TIMER_SOFTIRQ向量被激活到其run_timer_softirq()函数真正执行这段时间内可能会有几次时钟中断发生。因此内核必须记住上一次运行定时器机制是什么时候，也即内核必须保存上一次运行定时器机制时的jiffies值。为此，Linux在kernel/timer.c文件中定义了全局变量timer_jiffies来表示上一次运行定时器机制时的jiffies值。在run_timer_softirq中,首先检查jiffies是否大于timer_jiffies,只有大于timer_jiffies的时候,才会调用__run_timers函数(这个函数真正处理timer的函数)</p>

<h3>定时器迁移操作</h3>

<p>由于一个定时器的interval值会随着时间的不断流逝（即jiffies值的不断增大）而不断变小，因此那些原本到期紧迫程度较低的定时器会随着jiffies值的不断增大而成为既把马上到期的定时器。比如定时器向量tv2.vec[0]中的定时器在经过256个时钟滴答后会成为未来256个时钟滴答内会到期的定时器。因此，定时器在内核动态定时器链表中的位置也应相应地随着改变。改变的规则是：当tv1.index重新变为0时（意味着tv1中的256个定时器向量都已被内核扫描一遍了，从而使tv1中的256个定时器向量变为空），则用tv2.vec［index］定时器向量中的定时器去填充tv1，同时使tv2.index加1（它以64为模）。当tv2.index重新变为0（意味着tv2中的64个定时器向量都已经被全部填充到tv1中去了，从而使得tv2变为空），则用tv3.vec［index］定时器向量中的定时器去填充tv2。如此一直类推下去，直到tv5。函数cascade_timers()完成这种定时器迁移操作，该函数只有一个timer_vec结构类型指针的参数tv。</p>

<h3>__run_timers</h3>

<p>这个函数会把上次执行time 软中断到目前所有的超时函数都运行一遍.通过两个while循环来完成,外面的循环,每次执行每个tick里所有的超时函数,里面的循环执行一个tick里的每个超时函数</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[start]]></title>
    <link href="http://joycn.github.com/blog/2013/03/05/start/"/>
    <updated>2013-03-05T23:31:00+08:00</updated>
    <id>http://joycn.github.com/blog/2013/03/05/start</id>
    <content type="html"><![CDATA[<p>终于有了自己的Octopress blog了，按着网上的教程一步一步走过来了。由于自己本身对git不熟，所以在安装过程中还是遇到点问题的。记录下，万一有跟我一样的人遇到相同的问题呢。</p>

<p>按着蔓草笔记的<a href="http://xuhehuan.com/783.html">在Github上搭建Octopress博客</a>的介绍一步一步过来基本没什么问题的。</p>

<!-- more -->


<p>需要注意的是，在安装了git之后，需要进行相应的配置</p>

<figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>1. 在git的安装目录下找到git bash打开
</span><span class='line'>2. 然后执行 ssh-keygen -t rsa -C <span class="s2">&quot;your_email@youremail.com&quot;</span>生成密钥
</span><span class='line'>3. 然后把 用户名.ssh<span class="se">\下</span>生成的id_rsa.pub的内容copy下来
</span><span class='line'>4. 在github上的“Account Settings”&gt;&gt;“SSH Keys”&gt;&gt;“Add another key”，将刚才复制的内容粘贴到key文本框内。
</span></code></pre></td></tr></table></div></figure>


<p>然后还要预先建立github pages
新建repo后，根据提示，来新建pages。要不然后面即是deploy之后，访问也是会报404的..</p>

<p>第一篇blog完全成了吐槽贴。因为windows编码是GBK的问题，在new_post的时候，老是报错。然后想，总不能每次new_post的时候输入英文名字，然后再去里面改titile。想在服务器上再搞一套这东西，后来想，因为个博客，搞套这个东西太折腾，而且使用起来也不是很方便。然后向想一个比较“优雅”的办法。于是开始把cmd的默认字符集改成了utf-8，结果发现输入法又不能输入汉字了。然后想着找bash for windows之类的东西，结果还是失败了。最后想了想，擦。最简单的方式，就是自己写个python脚本，然后把字符转化下就好了。一行代码的事情。结果搞完了，发现生成的markdown文件名居然是拼音。。擦。。这么折腾下，发现也就是方便了我不用自己手动改titile。</p>

<p>顺便说下markdown编辑的问题，看起来很难，其实还好。写起来看起来很geek，但是由于我只是写blog，其他地方基本不会用，所以还是找个顺手的工具帮忙来定义格式之类的比较简单。markdownpad不错，但是就是对中文输入法的支持有点烂。先这么用着，有适合的再换~</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于vrrp的一点启发]]></title>
    <link href="http://joycn.github.com/blog/2013/03/05/something-about-vrrp/"/>
    <updated>2013-03-05T23:31:00+08:00</updated>
    <id>http://joycn.github.com/blog/2013/03/05/something-about-vrrp</id>
    <content type="html"><![CDATA[<p>之前lvs用的时候都是跑集群模式.对于主备模式基本没怎么研究过.这两天跑nat网关的时候,由于公司的量不大,就决定直接用主备模式了.但是因为之前keepalived不支持vmac,所以在主备切换的时候,是由备机,主动发起Gratuitous ARP来通告交换机说,vip对应的mac已经发生变化.但是这样有一个问题,<!-- more -->由于安全的考虑,一般交换机上都对arp做了限速.所以当vrrp跑的vip特别多的话,就会出现一个问题.并不是所有的arp的mac地址都做了更新.(因为有一部分arp被丢弃了.)所以这样就会有一部分流量还是会转发给原来的服务器而造成流量丢失.
今天跟同事讨论起来这个事情.告诉我一个比较好的办法来解决.就是在主备服务器上,都在loopback上把vip配上.然后在交换机上,通过路由的方式,将包转发到对应的服务器上.比如说主备都通过vrrp配一个10.15.0.51的vip.然后当主服务器down掉后,备机只要发送一个Gratuitous ARP就可以接管10.15.0.51这个vip.这样,后续的发给vip的数据包都会通过路由的形式转发到备服务器上.
这样做的好处就是,不仅解决了Gratuitous ARP在很多的情况下,被服务器过滤的问题.而且当主备切换时,只会有一个Gratuitous ARP发出.同时在服务器上启动的vip也只有这么一个.即使在主备频繁抖动的情况下,对网络的影响依旧很小.</p>
]]></content>
  </entry>
  
</feed>
